\documentclass[8pt]{beamer}

\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{stmaryrd}
\usepackage{xfrac}
\usepackage{dsfont}
\usepackage{fancybox}
\usepackage{multicol}
\usepackage{color}


\usepackage{lmodern}
\usepackage{tikz}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usepackage{wrapfig}

\newcommand{\tabitem}{%
  \usebeamertemplate{itemize item}\hspace*{\labelsep}}

\usetheme{Warsaw}

\title[IA et conduite autonome]{Utilisation de l'intelligence artificielle dans la manœuvre autonome de bateau}
\author{Maxime CAUTRÈS}
\institute{Lycée Blaise Pascal}
\date{01/03/2020}


\AtBeginSection[]
{
  \begin{frame}
  \frametitle{Sommaire}
  \tableofcontents[currentsection, hideothersubsections]
  \end{frame} 
}

%\logo{\includegraphics[height=10mm]{logo_limos_coul_def.png}}
%\logo{\includegraphics[height=15mm]{logo_noir.png}}
\logo{\includegraphics[height=10mm]{Logo-UCA.png}}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}


\section{Introduction}

\subsection{Mise en contexte}


\begin{frame}{allowframebreaks}{\label{deb}}
  
  \frametitle{Données économiques}
  \begin{figure}
    \begin{center}
      \includegraphics[height=50mm]{courbe_evo_bateau.png}
      \caption{La croissance du commerce maritime international (en millions de tonnes chargées) \footnote{http://geoconfluences.ens-lyon.fr/informations-scientifiques/dossiers-regionaux/territoires-europeens-regions-etats-union/rte-t/port-anvers}}
    \end{center}
  \end{figure}
  
\end{frame}


\begin{frame}
  \frametitle{Le métier de pilote maritime}

  \begin{figure}
    \begin{minipage}[c]{.52\linewidth}
        \centering
        \includegraphics[height=5cm]{pilotemaritime.jpg}
        \caption{Transfert du pilote maritime sur le bateau à piloter \footnotemark}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.40\linewidth}
        \centering
        \begin{itemize}
        \item Un métier \textbf{dangereux} (Le transfère du pilote)\break
          \pause
        \item Un \textbf{coût matériel} important (Bateau ou hélicoptère)\break
          \pause
        \item Un \textbf{coût financier} important (7\% du coût de l'escale)
        \end{itemize}
    \end{minipage}
    \footnotetext{http://escale.sinerj.org/spip.php?article41}
\end{figure}
  
\end{frame}


\begin{frame}
  \frametitle{Étude de l'existant}

   \begin{figure}
    \begin{minipage}[c]{.46\linewidth}
        \centering
        \includegraphics[width=55mm]{boat_docking.jpg}
        \caption{Vu aérienne de la trajectoire suivit par l'asservissement du bateau \footnotemark}
    \end{minipage}
    \footnotetext{https://smartmaritimenetwork.com/2019/02/08/yanmar-trials-robotic-ship-technology/}
    \hfill%
    \begin{minipage}[c]{.46\linewidth}
        \centering
        \begin{itemize}
        \item \textbf{Peu d'acteurs} dans le domaine (Deux principaux avec Yanmar et Volvo) \break
          \pause
        \item Nécessite des modifications importantes des \textbf{infrastructures} (capteurs, antennes) \break
          \pause
        \item Un dispositif \textbf{très lent et peu adapté} aux déplacements important dans un port 
        \end{itemize}
    \end{minipage}
     
\end{figure}
\end{frame}

\subsection{Une nouvelle approche}

\begin{frame}

  \frametitle{L'apprentissage automatique:}

  \begin{figure}
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \includegraphics[width=55mm]{simulation_boat.jpg}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \begin{itemize}
  \item Un environnement pour simuler les conditions réelles \break
    \break \break \break
  \end{itemize}
    \end{minipage}
  \end{figure}

\end{frame}
  
\begin{frame}

  \frametitle{L'apprentissage automatique:}

  \begin{figure}
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \includegraphics[width=45mm]{network_example.png}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \begin{itemize}
  \item Un environnement  \break
  \item La techonologie des réseaux de neuronnes\break
    \pause
  \item Des algorithmes d'entrainement
  \end{itemize}
    \end{minipage}
  \end{figure}

\end{frame}

\subsection{Problématique}

\begin{frame}

  \frametitle{Problématique}
  
  Comment peut-on utiliser l’\textbf{apprentissage automatique} pour
  permettre à un bateau de \textbf{manœuvrer dans un port} dans le but de
  minimiser les dépenses liées à l’augmentation du trafic tout en
  garantissant la sécurité ?
  \break \pause
  \begin{center}
    \begin{tabular}{@{}l@{}}
      Le plan: \\ \\ 
      \pause
      \tabitem Première approche avec le Q-learning \\ \\
      \pause
      \tabitem Simulation de l'environnement portuaire \\ \\
      \pause
      \tabitem Seconde approche avec le Policy Gradients
    \end{tabular}
    \end{center}
\end{frame}



\section{Le Q-learning}
\subsection{Le problème des souris}

\begin{frame}{allowframebreaks}{\label{2}}
  \frametitle{Un problème intermédiaire pour se lancer}
  \framesubtitle{Description}

  \begin{figure}
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \includegraphics[width=45mm]{map_q-learning.png}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \begin{itemize}
      \item En Noir les obstacles \break
      \item En blanc les cases accessibles \break
      \item La souris est en bleu \break
      \item L'objectif en la case en bas a droite \break
  \end{itemize}
    \end{minipage}
  \end{figure}
 
\end{frame}

\begin{frame}{allowframebreaks}{\label{2}}
  \frametitle{Un problème intermédiaire pour se lancer}
  \framesubtitle{Formalisation}
  \begin{figure}
    \begin{minipage}[c]{.55\linewidth}
      \centering
      \input{markov.tex}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.37\linewidth}
      \centering
      \begin{itemize}
      \item On utilise \textbf{les chaines de Markov deterministe}
    \item {\color{blue} Bleu} pour l'état initial
    \item {\color{green} Vert} pour l'état final
    \item {\color{red} Rouge} pour les murs
    \item \textbf{a, b, c, d} pour les actions
    \item Un système de \textbf{récompense}
      \end{itemize}
    \end{minipage}
  \end{figure}
\end{frame}



\begin{frame}{allowframebreaks}{\label{2}}
  \frametitle{Un problème intermédiaire pour se lancer}
  \framesubtitle{Définitions}
  \begin{figure}
    
    \begin{minipage}[c]{.55\linewidth}
      \centering
      \input{markov.tex}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.37\linewidth}
      \centering
      Le Q-learing:
      \begin{itemize}
      \item Une fonction de valuation: \begin{equation} V^{\pi}(s, a) \end{equation}
        \item Pour se déplacer:
          \begin{equation}{\label{mouvementmdp}}
            s' = \max_{a}(V^{\pi}(s, a))
          \end{equation}
        \item La récompense: \begin{equation} R(s, a) \end{equation}
      \end{itemize}
    \end{minipage}
  \end{figure}
\end{frame}


\begin{frame}

  \frametitle{Algorithme et équation de Bellman}

  \begin{block}{Initialisation}
    On définit les $V^{\pi}(s, a)$ aléatoirement
  \end{block}

  \begin{block}{Récurrence}
    \begin{itemize}
    \item On effectue une simulation grâce à la formule (\ref{mouvementmdp})
    \item Sur chaque état alors visité, on applique l'équation de Bellman:
     \begin{align}
       V^{\pi}_{t+1}(s, a)&=R(s, a)+\gamma \sum _{s'}P(s'|s, a)V^{\pi }_{t}(s') \\
       \Leftrightarrow\footnotemark V^{\pi}_{t+1}(s, a)&=R(s, a)+\gamma V_t^{\pi}(s')
     \end{align}
     
    \end{itemize}
    \footnotetext{Ici l'équivalence vient de fait que l'environnement est déterministe}
  \end{block}
  
  \begin{block}{Terminaison}
    On arrête l'algorithme une solution optimal est trouvée ou si une limite de temps est dépassée
  \end{block}

\end{frame}


\begin{frame}
\frametitle{Performance de la méthode}
\end{frame}

\begin{frame}
  \frametitle{Limite de la méthode}

  \begin{block}{Physique}
    \begin{itemize}
    \item Temps d'exécution
    \item Faible adaptivité
    \item Difficulté malgrès l'environnement simple
    \end{itemize}
  \end{block}

  \pause

  \begin{block}{Amélioration}
    \begin{itemize}
    \item Un environnement plus réaliste
    \item Une meilleur adaptivité
    \item Une vitesse de calcul plus importante
    \end{itemize}
  \end{block}
  
  
\end{frame}

\section{L'environnement}

\subsection{Le cahier des charges}

\begin{frame}

  \frametitle{Objectifs et contraintes}

\begin{block}{Objectif}
    \begin{itemize}
    \item Prise en compte de l'inertie
    \item Prise en compte des frottements visqueux
    \item Prise en compte des caractéristiques physiques du bateau
    \item Un environnement qui représente un port
    \item Il doit être adaptable 
    \end{itemize}
\end{block}

\pause

\begin{block}{Contrainte}
    \begin{itemize}
    \item Le modèle doit être très rapide d'exécution
    \item Autoriser l'exécution en parallèle
    \item Être représentable visuellement
    \end{itemize}
\end{block}

\end{frame}

\subsection{Notre implémentation}

\begin{frame}

  \frametitle{Visuellement}

  \begin{figure}
    \begin{minipage}[c]{.55\linewidth}
      \centering
      \includegraphics[width=55mm]{map_v.png}
      \caption{Rendu visuel de notre environnement \footnotemark}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.37\linewidth}
      \centering
      \begin{itemize}
      \item Un environnement \textbf{discrétisé}
    \item Blanc pour le bateau
    \item Beige pour les murs
    \item Violet pour l'objectif
    \item Les cases rouges et vertes \textbf{montre les actions}
      \end{itemize}
    \end{minipage}
  \end{figure}
  \footnotetext{Les actions sont \textbf{seulement affichées pour l'utilisateur}, elle ne font pas parti de l'environnement}

\end{frame}

\begin{frame}

  \frametitle{Visuellement}

  \begin{figure}
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \input{trajec_example.tex}
      \caption{Exemple de trajectoire de bateau}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.46\linewidth}
      \centering
      \begin{itemize}
      \item En {\color{red} rouge} les positions successives du bateau
      \item En {\color{purple} violet}, prise en compte de l'inertie (répétition du déplacement)
      \item En {\color{green} vert} les choix d'actions successifs (rayon 1 de autour de {\color{purple}violet} \footnotemark)
      \item Sous python, \textbf{Numpy} permet la \textbf{vectorisation} et donc les \textbf{parties simultanées} (1000 parties prennent le même temps que une ou deux parties)
      \end{itemize}
    \end{minipage}
  \end{figure}
  \footnotetext{Ici, la zone est carré mais la forme peut varier pour augmenter l'aspect réaliste du modèle et s'adapter au caractéristique même du bateau.}

\end{frame}


\section{Le Policy Gradients}

\subsection{La théorie}

\begin{frame}

  \frametitle{Définissions et notations}

  \begin{block}{La Politique et ses fonctions Gain, Q-Value, Value et Reward associées}
    \begin{itemize}
    \item La Politique
      \begin{equation} \pi_{\theta}(s) = (p_i)_{i \in \llbracket 1, ac \rrbracket} / {\scalebox{0.85}{$\displaystyle \sum_{i = 1}^{ac}$}}p_i = 1  \end{equation}
    \item Le Gain
      \begin{equation} G_t = {\scalebox{0.85}{$\displaystyle \sum_{k=0}^{\infty}$}} \gamma^k R_{t+k+1} \end{equation}
    \item La Q-value
      \begin{equation} Q^\pi(s, a) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s, A_t = a] \end{equation}
    \item La Value
      \begin{equation} V^\pi (s) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s] \end{equation}
    \item La Recompense, fonction Reward
      \begin{equation} J(\theta) 
= {\scalebox{0.85}{$\displaystyle \sum_{s \in \mathcal{S}}$}} d^\pi(s) V^\pi(s) 
= {\scalebox{0.85}{$\displaystyle \sum_{s \in \mathcal{S}}$}} d^\pi(s) {\scalebox{0.85}{$\displaystyle  \sum_{a \in \mathcal{A}}$}} \pi_\theta(a \vert s) Q^\pi(s, a) \end{equation}
    \end{itemize}
  \end{block}
  
\end{frame}

\begin{frame}[label=retourCNN]

  \frametitle{La Politique}

  \begin{block}{Un réseaux de neuronnes de convolution maison\footnotemark pour $\pi_{\theta}(s)$}
    \begin{itemize}
    \item $s$ correspond à l'entrée
    \item $\pi_{\theta}(s)$ correspond à la sortie
    \item $\theta$ correspond aux poids et biais du réseaux
    \end{itemize}

  \end{block}

  \begin{figure}
    
    \begin{minipage}[c]{.28\linewidth}
      \centering
      \includegraphics[width=\linewidth]{map_v.png}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.04\linewidth}
      \centering
      $=$
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.43\linewidth}
      \centering
      \includegraphics[width=1.05\linewidth]{CNN.png}
    \end{minipage}
    \hfill%
    \begin{minipage}[c]{.218\linewidth}
      \centering \[ =
      \left[
      \begin{array}{c}
        {\color{red}0.01}\\
        {\color{green} 0.85}\\
        {\color{red}0.01}\\
        {\color{red}0.03}\\
        {\color{red}0.04}\\
        {\color{red}0.01}\\
        {\color{red}0.02}\\
        {\color{red}0.01}\\
        {\color{red}0.02}
      \end{array}
      \right] \]
    \end{minipage}
  \end{figure}
  \footnotetext{Nous utilisons ici \hyperlink{CNN}{notre implémentation sans librairies spécialisées du Convolutional Neural Network}}
\end{frame}

\begin{frame}[label=policyintroduction]
  \frametitle{L'entrainement}
  \begin{block}{L'initialisation}
    On définit une structure pour le réseau de neurones où les poids et biais sont définis aléatoirement
  \end{block}

  \begin{block}{Par récurrence (En époques) \footnotemark}
    \begin{itemize}
    \item On effectue P parties en parallèle, on récupère:
      \begin{center}
      {\scalebox{0.85}{
      $\left\{
      \begin{array}{c}
        S_0^1, A_0^1, R_0^1, \cdots, S_{f_1-1}^1, A_{f_1-1}^1, R_{f_1-1}^1, S^1_{f_1} \\
        \vdots \\
        S_0^P, A_0^P, R_0^P, \cdots, S_{f_P-1}^P, A_{f_P-1}^P, R_{f_P-1}^P, S^P_{f_P} 
      \end{array}
      \right. $}} \end{center}
    \item Pour tout $i \in \llbracket 1, P \rrbracket$ et $t \in \llbracket 0, f_i - 1 \rrbracket$
      \begin{align}
        G_t^i &= {\scalebox{0.85}{$\displaystyle \sum_{k=O}^{f_i-t-2}$}} \gamma^k R^i_{t+k+1} \\
        \theta &\leftarrow \theta + \alpha \gamma^t G^i_t \nabla_\theta \ln \pi_\theta(A^i_t \vert S^i_t)
      \end{align}
    
    \end{itemize}

  \end{block}

  \footnotetext{Ceci résulte d'un \hyperlink{demopolicygradient}{théorème majeur sur le Policy Gradients}}
\end{frame}

\subsection{Résultats}

\begin{frame}

\end{frame}

\section*{Conclusion}

\subsection{Objectif}

\subsection{Ouverture}

\appendix

\section*{Notre implémentation du CNN}

\begin{frame}[label=CNN]
  \frametitle{Un fait maison}
  \hyperlink{retourCNN}{Retour}
\end{frame}

\section*{Proof of the Policy Gradient Theroem}

\begin{frame}[label=demopolicygradient]
  \frametitle{Bonsoir ici on se marre}

  \hyperlink{policyintroduction}{Retour}
  
  klbuerbqhvhjbyerukbvhjqkjbrey
\end{frame}
\end{document}

